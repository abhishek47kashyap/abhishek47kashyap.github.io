---
title: 'AutoEncoders: minimal working examples'
date: 2023-09-11
permalink: /posts/2023/09/autoencoders_minimum_working_examples/
# tags:
#   - cool posts
#   - category1
#   - category2
---

AutoEncoders allow extracting a low-dimensional embedding of an input image and reconstructing the original image from the low-dimensional embedding. While Principal Component Analysis also allows extracting such features, autoencoders are capable of learning more efficient representations due to the non-linearities of a neural network.

Sampling from the low-dimensional embedding space (also called the _latent space_) can help reconstruct new images that the network was not originally trained on, thus making autoencoders a member of the family of [generative models](https://openai.com/research/generative-models). There are some caveats about sampling from the latent space of autoencoders due to lack of "continuity", which is where Variational Auto Encoders (VAE) come in. This article however is limited to AutoEncoders.

The origin of the idea of autoencoders can be difficult to track down, see [What is the origin of the autoencoder neural networks?](https://stats.stackexchange.com/questions/238381/what-is-the-origin-of-the-autoencoder-neural-networks).

## Architecture
An AutoEncoder (henceforth referred to as AE) has an encoder-decoder architecture, with the decoder "undoing" the operations of the encoder on the original image. Squashed between the encoder and the decoder is the latent space (referred to as `Code` in the picture below), which is what learns the low-dimensional embeddings of a training dataset.

![Autoencoder_schema](/images/autoencoders/Autoencoder_schema.png)

